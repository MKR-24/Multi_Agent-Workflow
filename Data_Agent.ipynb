{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682753f6-1e7b-47e5-a3e0-d395e7b9be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ =load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763c0fc-65d3-4295-ae71-0745d5b5e0fb",
   "metadata": {},
   "source": [
    "2.1 Initialize the agent's state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0531f14-df85-4ece-bb1f-8432292ea134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\mohak\\anaconda3\\lib\\site-packages (0.6.8)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph) (0.3.78)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph) (2.10.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.32)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (2.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41575ed5-2fc7-48f0-91ce-4247d057d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal , Optional, List, Dict, Any ,Type\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "#Custom State class with specific keys\n",
    "class State(MessagesState):\n",
    "    user_query: Optional[str]  # The user's original query\n",
    "    enabled_agents: Optional[List[str]]  # Makes our multi-agent system modular on which agents to include\n",
    "    plan: Optional[List[Dict[int, Dict[str,Any]]]] # Listing the steps in the plan needed to achieve the goal.\n",
    "    current_step: int #Marking the current step in the plan.\n",
    "    agent_query: Optional[str] # Inbox note: `agent_query` tells the next agent exactly what to do at the current step.\n",
    "    last_reason: Optional[str] # Explains the exceutor's decision to help maintain continuity and provide traceability.\n",
    "    replan_flag: Optional[bool] # Set by the executor to indicate that the planner should revise the plan.\n",
    "    replan_attempts: Optional[Dict[int,Dict[int,int]]] # Replan attempts tracked per step number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac35695-4da2-4cb2-8f08-1a59e9cf69d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in c:\\users\\mohak\\anaconda3\\lib\\site-packages (0.3.34)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.77 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain_openai) (0.3.78)\n",
      "Collecting openai<3.0.0,>=1.104.2 (from langchain_openai)\n",
      "  Using cached openai-2.1.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain_openai) (0.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.77->langchain_openai) (0.4.32)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.77->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.77->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.77->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.77->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.77->langchain_openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.77->langchain_openai) (2.10.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.77->langchain_openai) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.77->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.77->langchain_openai) (2.27.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.77->langchain_openai) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.104.2->langchain_openai) (0.4.6)\n",
      "Using cached openai-2.1.0-py3-none-any.whl (964 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.99.9\n",
      "    Uninstalling openai-1.99.9:\n",
      "      Successfully uninstalled openai-1.99.9\n",
      "Successfully installed openai-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trulens-providers-openai 2.4.0 requires openai<1.100.0,>=1.52.1, but you have openai 2.1.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4bdc7f5-b995-43d8-bcc5-95cceb51357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\mohak\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain) (0.3.78)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain) (0.4.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fedf3b-25fd-46ed-a191-71209bacd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import plan_prompt\n",
    "from langgraph.types import Command\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c57e609e-8da1-43cc-b40b-9acd12888b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = ChatOpenAI(\n",
    "    model= \"o3\",\n",
    "    model_kwargs= {\" response_format\": {\"type\":\"json_objet\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1a7aa-08be-4742-8ce1-be12ad3dcad1",
   "metadata": {},
   "source": [
    "2.2 Create planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e48a4d-48bd-40fa-9005-adcbb458a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: State) -> Command[Literal['executor']]:\n",
    "    \"\"\"\n",
    "    Runs the planning LLM and stores the resulting plan in state.\n",
    "    \"\"\"\n",
    "    # 1. Invoke LLM with the planner prompt\n",
    "    llm_reply = reasoning_llm.invoke([plan_prompt(state)])\n",
    "\n",
    "    # 2. Validate JSON\n",
    "    try:\n",
    "        content_str = llm_reply.content if isinstance( llm_reply.content, str)else str(llm_reply.content)\n",
    "        parsed_plan= json.loads(content_str)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(\n",
    "            f\"Planner returned invalid JSON:\\n{llm_reply.content}\")\n",
    "    # 3. Store as current plan only\n",
    "    replan = state.get(\"replan_flag\", False)\n",
    "    updated_plan: Dict[str, Any] = parsed_plan\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"plan\" : updated_plan,\n",
    "            \"messages\": [HumanMessage(\n",
    "                content=llm_reply.content,\n",
    "                name=\"replan\" if replan else \"initial_plan\")],\n",
    "            \"user_query\": state.get(\"user_query\", state[\"messages\"][0].content),\n",
    "                                    \"current_step\": 1 if not replan else state[\"current_step\"],\n",
    "            # Preserve replan flag so executor runs planned agent\n",
    "            # once before reconsidering\n",
    "            \"replan_flag\": state.get(\"replan_flag\", False),\n",
    "            \"last_reason\":\"\",\n",
    "            \"enabled_agents\": state.get(\"enabled_agents\"),\n",
    "        },\n",
    "        goto=\"executor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb2418-bd9b-4427-912f-7aade107406c",
   "metadata": {},
   "source": [
    "2.3 Create executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016f5e2d-d636-4793-a70a-8df760214469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import executor_prompt\n",
    "from langgraph.graph import END\n",
    "\n",
    "MAX_REPLANS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf5d199-6de8-4a83-b881-15235cd1ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executor_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"web_researcher\", \"chart_generator\", \"synthesizer\",\"planner\"]]:\n",
    "    plan: Dict[str, Any] = state.get(\"plan\",{})\n",
    "    step: int = state.get(\"current_step\",1)\n",
    "    # 0) If we *just* replanned, \n",
    "    # run the planned agent once before reconsidering.\n",
    "    if state.get(\"replan_flag\"):\n",
    "        planned_agent=plan.get(str(step),{}).get(\"agent\")\n",
    "        return Command(\n",
    "            update={\n",
    "                \"replan_flag\":False,\n",
    "                \"current_step\": step+1, # advance because we executed the planned agent\n",
    "            },\n",
    "            goto=planned_agent,\n",
    "        )\n",
    "    # 1) Build prompt & call LLM\n",
    "    llm_reply = reasoning_llm.invoke([executor_prompt(state)])\n",
    "    try:\n",
    "        content_str = llm_reply.content if isinstance(llm_reply.content,str)else str(llm_reply.content)\n",
    "        parsed=json.loads(content_str)\n",
    "        replan: bool =parsed[\"replan\"]\n",
    "        goto: str = parsed[\"goto\"]\n",
    "        reason: str = parsed[\"reason\"]\n",
    "        query: str =parsed[\"query\"]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\" Invalid executor JSON: \\n{llm_reply.content}\") from e\n",
    "\n",
    "    # Update the state\n",
    "    updates: Dict[str, Any] ={\n",
    "    \"messages\": [HumanMessage(content=llm_reply.content, name=\"executor\")],\n",
    "    \"last_reason\": reason,\n",
    "    \"agent_query\": query,\n",
    "    }\n",
    "\n",
    "    # Replan accounting\n",
    "    replans: Dict[int,int] =state.get(\"replan_attempts\",{}) or {}\n",
    "    step_replans = replans.get(step,0)\n",
    "\n",
    "    # 2) Replan decision\n",
    "    if replan:\n",
    "        if step_replans < MAX_REPLANS:\n",
    "            replans[step] = step_replans +1\n",
    "            updates.update({\n",
    "                \"replan_attempts\": replans,\n",
    "                \"replan_flag\": True,  # ensure next turn executes the planned agent once\n",
    "                \"current_step\" :step, # stay on same step for the new plan\n",
    "            })\n",
    "            return Command(update=updates, goto=\"planner\")\n",
    "        else:\n",
    "              # Cap hit: skip this step; let next step (or synthesizer) handle termination\n",
    "            next_agent= plan.get(str(step+1),{}).get(\"agent\", \"synthesizer\")\n",
    "            updates[\"current_step\"] = step + 1\n",
    "            return Command(update= updates, goto= next_agent)\n",
    "    # 3) Happy path: run chosen agent; advance only if following the plan\n",
    "    planned_agent = plan.get (str(step),{}).get(\"agent\")\n",
    "    updates[\"current_step\"] = (step + 1) if goto == planned_agent else step\n",
    "    updates[\"replan_flag\"] = False\n",
    "    return Command(update= updates, goto=goto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c742211-4a20-48c7-a98a-878f42bd11d3",
   "metadata": {},
   "source": [
    "2.4 Create Web research agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d1e8dc-72bd-40f3-83e4-88f94871cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_tavily in c:\\users\\mohak\\anaconda3\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain_tavily) (3.12.15)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain_tavily) (0.3.27)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain_tavily) (0.3.78)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain_tavily) (2.32.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.18.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain_tavily) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain_tavily) (0.4.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain_tavily) (2.10.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain_tavily) (2.0.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain_tavily) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_tavily) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_tavily) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_tavily) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_tavily) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4.0,>=0.3.15->langchain_tavily) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain_tavily) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain_tavily) (2.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain_tavily) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain_tavily) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain_tavily) (3.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain_tavily) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95539998-db1e-48a6-aa65-ccf96802f125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://tradingeconomics.com/nvda:us',\n",
       "  'title': 'Nvidia | NVDA - Stock Price | Live Quote | Historical Chart',\n",
       "  'content': 'Nvidia Corporation traded at $187.62 this Friday October 3rd, decreasing $1.27 or 0.67 percent since the previous trading session. Looking back, over the',\n",
       "  'score': 0.8941352,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.marketwatch.com/investing/stock/nvda?gaa_at=eafs&gaa_n=ASWzDAgZUNEzM8fMRnlgzIprQCZ-hnTYzeKNO0dxMFlbTQrLHgHarZyyr3FW&gaa_ts=68e30d1b&gaa_sig=U2i56HyLEW9_Z8m1vcBdNi-RWtYyzA4bisd4OAxeFPFyBlwxF9yZgjLO0xdpNAINK1S2P7oJs8vr7IHZjqh14Q%3D%3D',\n",
       "  'title': 'NVIDIA Corp. Stock Quote (U.S.: Nasdaq) - NVDA - MarketWatch',\n",
       "  'content': 'NVIDIA Corp. ; Open $189.19 ; Day Range 185.38 - 190.36 ; 52 Week Range 86.62 - 191.05 ; Market Cap $4.56T ; Public Float 23.31B',\n",
       "  'score': 0.8846886,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.tradingview.com/symbols/NASDAQ-NVDA/',\n",
       "  'title': 'NVIDIA Stock Chart â€” NASDAQ:NVDA Stock Price - TradingView',\n",
       "  'content': 'Based on the daily chart of NVIDIA (NVDA) on NASDAQ, hereâ€™s a breakdown: ðŸ”Ž Technical Analysis Overall Trend The stock is in a strong uptrend (rallying from around $120 to the current $186). NVIDIA Corporation (NVDA) almost hit today its All Time High (ATH), which is currently its Resistance level. Watch NVDA chart and read a more detailed NVIDIA Corporation stock forecast: see what analysts think of NVIDIA Corporation and suggest that you do with its stocks. Track NVIDIA Corporationstock price on the chart and check out the list of the most volatile stocks â€” is NVIDIA Corporation there? NVIDIA Corporation revenue for the last quarter amounts to \\u202a46.74\\u202fB\\u202c\\xa0USD, despite the estimated figure of \\u202a46.05\\u202fB\\u202c\\xa0USD.',\n",
       "  'score': 0.8773195,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.cnn.com/markets/stocks/NVDA',\n",
       "  'title': 'NVDA Stock Quote Price and Forecast - CNN',\n",
       "  'content': 'The price of NVDA shares has decreased $1.27 since the market last closed. This is a 0.67% drop. Closed at $187.62. The stock has since risen $0.04 in after',\n",
       "  'score': 0.8458536,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.morningstar.com/stocks/xnas/nvda/quote',\n",
       "  'title': 'NVIDIA Stock Price Quote - NASDAQ: NVDA - Morningstar',\n",
       "  'content': \"*   [Price vs Fair Value](https://www.morningstar.com/stocks/xnas/nvda/price-fair-value) *   [Trailing Returns](https://www.morningstar.com/stocks/xnas/nvda/trailing-returns) *   [Key Metrics](https://www.morningstar.com/stocks/xnas/nvda/key-metrics) *   [Financials](https://www.morningstar.com/stocks/xnas/nvda/financials) *   [Valuation](https://www.morningstar.com/stocks/xnas/nvda/valuation) *   [Dividends](https://www.morningstar.com/stocks/xnas/nvda/dividends) [View History](https://www.morningstar.com/stocks/xnas/nvda/price-fair-value) [View All](https://www.morningstar.com/stocks/xnas/nvda/news) ![Image 4](https://www.morningstar.com/assets/img/marketwatch.dad5abb.png) MarketWatch Sep 25, 2025, 5:24:00 PM](https://www.morningstar.com/news/marketwatch/20250925237/can-google-overtake-nvidia-as-the-worlds-most-valuable-company-heres-why-thats-not-so-crazy) Why AI spending estimates now seem less 'outlandish.' ![Image 5](https://www.morningstar.com/assets/img/marketwatch.dad5abb.png) MarketWatch Sep 25, 2025, 1:13:00 PM](https://www.morningstar.com/news/marketwatch/20250925169/nvidias-stock-can-soar-35-more-barclays-says-why-ai-spending-estimates-now-seem-less-outlandish) ![Image 6](https://www.morningstar.com/assets/img/marketwatch.dad5abb.png) MarketWatch Sep 23, 2025, 11:34:00 PM](https://www.morningstar.com/news/marketwatch/20250923327/nvidias-openai-deal-adds-to-a-brewing-concern-but-will-that-actually-hurt-the-stock) ![Image 7](https://www.morningstar.com/assets/img/marketwatch.dad5abb.png) MarketWatch Sep 23, 2025, 2:41:00 PM](https://www.morningstar.com/news/marketwatch/2025092357/will-coreweave-bears-get-burned-new-nvidia-deals-spark-fresh-optimism-for-the-stock) ![Image 13](https://morningstar-morningstar-prod.web.arc-cdn.net/resizer/jTKvHutNWfWWuGCfVYrMLnj9bw4=/2000x2000/author-service-images-prod-us-east-1.publishing.aws.arc.pub/morningstar/9b6965de-342f-4681-b6f6-0db57d4daae0.png) Sarah Hansen Sep 24, 2025](https://www.morningstar.com/markets/will-ai-boom-semiconductor-stocks-continue) *   [#### Nvidia: Firm Shares Big AI Dreams with OpenAI, Announce a Strategic Partnership ![Image 14](https://morningstar-morningstar-prod.web.arc-cdn.net/resizer/1bY4VtvaX_BEy66KbrjdD8VeE4k=/2000x2000/author-service-images-prod-us-east-1.publishing.aws.arc.pub/morningstar/5c8852db-04a9-4ec5-8527-9107fff80c09.jpg) Brian Colello, CPA Sep 22, 2025](https://www.morningstar.com/stocks/nvidia-firm-shares-big-ai-dreams-with-openai-announce-strategic-partnership) ![Image 16](https://morningstar-morningstar-prod.web.arc-cdn.net/resizer/Z4M3dr2w3KnQ0zZmAAkrFWoDKUw=/2000x2000/author-service-images-prod-us-east-1.publishing.aws.arc.pub/morningstar/687c42c2-15b8-4c8d-a9f6-6fadac96dd73.jpg) Dan Kemp Sep 22, 2025](https://www.morningstar.com/markets/markets-brief-ai-stocks-are-spending-huge-sums-will-this-time-be-different) *   [#### Taiwan Semiconductor: Nvidiaâ€™s Collaboration with Intel Has Minimal Impact on Long-Term Outlook ![Image 18](https://morningstar-morningstar-prod.web.arc-cdn.net/resizer/IzBxCrlgnF8q07kewXQ2ALuXhWc=/2000x2000/author-service-images-prod-us-east-1.publishing.aws.arc.pub/morningstar/51408a44-34a8-4b9e-9370-8acd8e7699af.jpg) Phelix Lee Sep 19, 2025](https://www.morningstar.com/stocks/taiwan-semiconductor-nvidias-collaboration-with-intel-has-minimal-impact-long-term-outlook) [View More](https://www.morningstar.com/stocks/xnas/nvda/valuation)\",\n",
       "  'score': 0.7917732,\n",
       "  'raw_content': None}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Literal\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "tavily_tool = TavilySearch(max_results=5)\n",
    "tavily_tool.invoke(\" What is NVIDIA 's stock price?\")['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8bfbe62-ec5d-46e6-aca8-3b7561faa4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trulens-providers-openai in c:\\users\\mohak\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: langchain-community>=0.0.20 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-providers-openai) (0.3.30)\n",
      "Collecting openai<1.100.0,>=1.52.1 (from trulens-providers-openai)\n",
      "  Using cached openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: trulens-core<3.0.0,>=2.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-providers-openai) (2.4.0)\n",
      "Requirement already satisfied: trulens-feedback<3.0.0,>=2.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-providers-openai) (2.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<1.100.0,>=1.52.1->trulens-providers-openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<1.100.0,>=1.52.1->trulens-providers-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<1.100.0,>=1.52.1->trulens-providers-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<1.100.0,>=1.52.1->trulens-providers-openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<1.100.0,>=1.52.1->trulens-providers-openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<1.100.0,>=1.52.1->trulens-providers-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<1.100.0,>=1.52.1->trulens-providers-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from openai<1.100.0,>=1.52.1->trulens-providers-openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<1.100.0,>=1.52.1->trulens-providers-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<1.100.0,>=1.52.1->trulens-providers-openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<1.100.0,>=1.52.1->trulens-providers-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<1.100.0,>=1.52.1->trulens-providers-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<1.100.0,>=1.52.1->trulens-providers-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai<1.100.0,>=1.52.1->trulens-providers-openai) (2.27.1)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.8.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.16.5)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.8 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (0.3.8)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (6.5.2)\n",
      "Requirement already satisfied: munch<3.0.0,>=2.5.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.5.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0,>=1.5 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.1.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto>=1.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.37.0)\n",
      "Requirement already satisfied: packaging>=23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (24.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.2.3)\n",
      "Requirement already satisfied: python-dotenv<2.0,>=0.21 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.32.5)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (13.9.4)\n",
      "Requirement already satisfied: sqlalchemy<3.0,>=2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.0.39)\n",
      "Requirement already satisfied: trulens-otel-semconv<3.0.0,>=2.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.17.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.17.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from alembic<2.0.0,>=1.8.1->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.3.10)\n",
      "Requirement already satisfied: six in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from munch<3.0.0,>=2.5.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.31->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.31->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.6.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.6.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from sqlalchemy<3.0,>=2.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (3.1.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-feedback<3.0.0,>=2.0.0->trulens-providers-openai) (3.9.1)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-feedback<3.0.0,>=2.0.0->trulens-providers-openai) (1.6.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.11.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-feedback<3.0.0,>=2.0.0->trulens-providers-openai) (1.15.3)\n",
      "Requirement already satisfied: click in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->trulens-feedback<3.0.0,>=2.0.0->trulens-providers-openai) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->trulens-feedback<3.0.0,>=2.0.0->trulens-providers-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->trulens-feedback<3.0.0,>=2.0.0->trulens-providers-openai) (2024.11.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=1.3.0->trulens-feedback<3.0.0,>=2.0.0->trulens-providers-openai) (3.5.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions>=0.36b0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from trulens-otel-semconv<3.0.0,>=2.0.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (0.58b0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (0.3.78)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (0.3.27)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (0.4.32)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community>=0.0.20->trulens-providers-openai) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.0.20->trulens-providers-openai) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.0.20->trulens-providers-openai) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.0.20->trulens-providers-openai) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community>=0.0.20->trulens-providers-openai) (0.3.11)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community>=0.0.20->trulens-providers-openai) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.75->langchain-community>=0.0.20->trulens-providers-openai) (2.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community>=0.0.20->trulens-providers-openai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community>=0.0.20->trulens-providers-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community>=0.0.20->trulens-providers-openai) (0.23.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community>=0.0.20->trulens-providers-openai) (0.4.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.0.20->trulens-providers-openai) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (0.1.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.23.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.23.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (3.21.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from opentelemetry-proto>=1.23.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (5.29.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from tqdm>4->openai<1.100.0,>=1.52.1->trulens-providers-openai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from Mako->alembic<2.0.0,>=1.8.1->trulens-core<3.0.0,>=2.0.0->trulens-providers-openai) (3.0.2)\n",
      "Using cached openai-1.99.9-py3-none-any.whl (786 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 2.1.0\n",
      "    Uninstalling openai-2.1.0:\n",
      "      Successfully uninstalled openai-2.1.0\n",
      "Successfully installed openai-1.99.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.3.34 requires openai<3.0.0,>=1.104.2, but you have openai 1.99.9 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install trulens-providers-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de88338-fdad-4bad-8bd2-6504ab37b670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_experimental in c:\\users\\mohak\\anaconda3\\lib\\site-packages (0.3.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain_experimental) (0.3.30)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain_experimental) (0.3.78)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.39)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.32)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mohak\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfb6b9a3-3716-4c24-b165-268a6bf1ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import agent_system_prompt\n",
    "\n",
    "llm= ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "#Research agent and node\n",
    "web_search_agent= create_react_agent(\n",
    "    llm,\n",
    "    tools= [tavily_tool],\n",
    "    prompt=agent_system_prompt(f\"\"\"\n",
    "          You are the Researcher. You can ONLY perform research \n",
    "        by using the provided search tool (tavily_tool). \n",
    "        When you have found the necessary information, end your output.  \n",
    "        Do NOT attempt to take further actions.\n",
    "        \"\"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a16690d-9464-4433-ad3e-ffb901ee5e2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent_response\u001b[38;5;241m=\u001b[39m web_search_agent\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m what is NVIDIA\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms current market cap?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3065\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3066\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3068\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3069\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3070\u001b[0m     config,\n\u001b[0;32m   3071\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3075\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3076\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3077\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3078\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3079\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3081\u001b[0m ):\n\u001b[0;32m   3082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3083\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\main.py:2657\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2655\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2656\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2658\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2659\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2660\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2661\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2662\u001b[0m ):\n\u001b[0;32m   2663\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2664\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2665\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2666\u001b[0m     )\n\u001b[0;32m   2667\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     run_with_retry(\n\u001b[0;32m    163\u001b[0m         t,\n\u001b[0;32m    164\u001b[0m         retry_policy,\n\u001b[0;32m    165\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    166\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[0;32m    167\u001b[0m                 _call,\n\u001b[0;32m    168\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[0;32m    169\u001b[0m                 retry_policy\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[0;32m    170\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[0;32m    171\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[0;32m    172\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m    173\u001b[0m             ),\n\u001b[0;32m    174\u001b[0m         },\n\u001b[0;32m    175\u001b[0m     )\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:394\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 394\u001b[0m         ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    396\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:627\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[1;34m(state, runtime, config)\u001b[0m\n\u001b[0;32m    625\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, dynamic_model\u001b[38;5;241m.\u001b[39minvoke(model_input, config))  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, static_model\u001b[38;5;241m.\u001b[39minvoke(model_input, config))  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[0;32m    630\u001b[0m response\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3246\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3244\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3245\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3246\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n\u001b[0;32m   3247\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5711\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5704\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5706\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5709\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5710\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5712\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5713\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5714\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5715\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    392\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 395\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    396\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    397\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    398\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    399\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    400\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    401\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    402\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    403\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    404\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    405\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1023\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1024\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    841\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 842\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    843\u001b[0m                 m,\n\u001b[0;32m    844\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    845\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    846\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    847\u001b[0m             )\n\u001b[0;32m    848\u001b[0m         )\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1091\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1092\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1093\u001b[0m     )\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1095\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1177\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_response\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1176\u001b[0m         e\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;241m=\u001b[39m raw_response\u001b[38;5;241m.\u001b[39mhttp_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m-> 1177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_response_headers\n\u001b[0;32m   1180\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1182\u001b[0m ):\n\u001b[0;32m   1183\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1172\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[0;32m   1166\u001b[0m             response,\n\u001b[0;32m   1167\u001b[0m             schema\u001b[38;5;241m=\u001b[39moriginal_schema_obj,\n\u001b[0;32m   1168\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mgeneration_info,\n\u001b[0;32m   1169\u001b[0m             output_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_version,\n\u001b[0;32m   1170\u001b[0m         )\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1172\u001b[0m         raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mwith_raw_response\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m   1173\u001b[0m         response \u001b[38;5;241m=\u001b[39m raw_response\u001b[38;5;241m.\u001b[39mparse()\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m extra_headers[RAW_RESPONSE_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\trulens\\core\\feedback\\endpoint.py:791\u001b[0m, in \u001b[0;36mEndpoint.wrap_function.<locals>.tru_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    785\u001b[0m context_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    786\u001b[0m     Endpoint\u001b[38;5;241m.\u001b[39m_context_endpoints: Endpoint\u001b[38;5;241m.\u001b[39m_context_endpoints\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m    787\u001b[0m }\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Get the result of the wrapped function:\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# response = context_vars.run(func, *args, **kwargs)\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    793\u001b[0m \u001b[38;5;66;03m# if len(Endpoint._context_endpoints.get()) == 0:\u001b[39;00m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;66;03m#    raise ValueError(\"No endpoints.\")\u001b[39;00m\n\u001b[0;32m    796\u001b[0m bindings \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[0m, in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[0m, in \u001b[0;36mcreate\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m    **Starting a new project?** We recommend trying\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m    [Responses](https://platform.openai.com/docs/api-reference/responses) to take\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1108\u001b[0m     messages: Iterable[ChatCompletionMessageParam],\n\u001b[0;32m   1109\u001b[0m     model: Union[\u001b[38;5;28mstr\u001b[39m, ChatModel],\n\u001b[0;32m   1110\u001b[0m     audio: Optional[ChatCompletionAudioParam] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1111\u001b[0m     frequency_penalty: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1112\u001b[0m     function_call: completion_create_params\u001b[38;5;241m.\u001b[39mFunctionCall \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1113\u001b[0m     functions: Iterable[completion_create_params\u001b[38;5;241m.\u001b[39mFunction] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1114\u001b[0m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1115\u001b[0m     logprobs: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1116\u001b[0m     max_completion_tokens: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1117\u001b[0m     max_tokens: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1118\u001b[0m     metadata: Optional[Metadata] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1119\u001b[0m     modalities: Optional[List[Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1120\u001b[0m     n: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1121\u001b[0m     parallel_tool_calls: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1122\u001b[0m     prediction: Optional[ChatCompletionPredictionContentParam] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1123\u001b[0m     presence_penalty: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1124\u001b[0m     prompt_cache_key: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1125\u001b[0m     reasoning_effort: Optional[ReasoningEffort] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1126\u001b[0m     response_format: completion_create_params\u001b[38;5;241m.\u001b[39mResponseFormat \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1127\u001b[0m     safety_identifier: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1128\u001b[0m     seed: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1129\u001b[0m     service_tier: Optional[Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1130\u001b[0m     stop: Union[Optional[\u001b[38;5;28mstr\u001b[39m], List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1131\u001b[0m     store: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1132\u001b[0m     stream: Optional[Literal[\u001b[38;5;28;01mFalse\u001b[39;00m]] \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1133\u001b[0m     stream_options: Optional[ChatCompletionStreamOptionsParam] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1134\u001b[0m     temperature: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1135\u001b[0m     tool_choice: ChatCompletionToolChoiceOptionParam \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1136\u001b[0m     tools: Iterable[ChatCompletionToolUnionParam] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1137\u001b[0m     top_logprobs: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1138\u001b[0m     top_p: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1139\u001b[0m     user: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1140\u001b[0m     verbosity: Optional[Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1141\u001b[0m     web_search_options: completion_create_params\u001b[38;5;241m.\u001b[39mWebSearchOptions \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;66;03m# Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;66;03m# The extra values given here take precedence over values defined on the client or passed to this method.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     extra_headers: Headers \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1145\u001b[0m     extra_query: Query \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1146\u001b[0m     extra_body: Body \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m-> 1147\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1148\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1149\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1152\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1198\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m   1199\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "\u001b[0mDuring task with name 'agent' and id '06e655fa-e9dc-f2a1-0ef3-50641d26a208'"
     ]
    }
   ],
   "source": [
    "agent_response= web_search_agent.invoke(\n",
    "    {\"messages\":\" what is NVIDIA's current market cap?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7470ad9-686c-4bec-a5e2-b8b4d659e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5c776-45c0-4118-b9cc-15205c3608c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_research_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[\"executor\"]]:\n",
    "    agent_query= state.get(\"agent_query\")\n",
    "    result= web_search_agent.invoke({\"messages\":agent_query})\n",
    "    goto=\"executor\"\n",
    "      # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1]=HumanMessage(\n",
    "    content=result[\"messages\"][-1].content, name=\"web_researcher\"\n",
    "    )\n",
    "    return Command(\n",
    "    update={\n",
    "        # share internal message history of research agent with other agents\n",
    "        \"messages\": result[\"messages\"],\n",
    "    },\n",
    "    goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c5066-26d3-4942-a469-e8993fb39732",
   "metadata": {},
   "source": [
    "2.5 Create charting agent\r",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f61594-f3df-49ab-be32-32b45a3d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import python_repl_tool\n",
    "# Chart generator agent and node\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, \n",
    "# WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "chart_agent = create_react_agent(\n",
    "    llm,\n",
    "    [python_repl_tool],\n",
    "    prompt=agent_system_prompt(\n",
    "        \"\"\"\n",
    "        You can only generate charts. You are working with a researcher \n",
    "        colleague.\n",
    "        1) Print the chart first.\n",
    "        2) Save the chart to a file in the current working directory.\n",
    "        3) At the very end of your message, output EXACTLY two lines \n",
    "        so the summarizer can find them:\n",
    "           CHART_PATH: <relative_path_to_chart_file>\n",
    "           CHART_NOTES: <one concise sentence summarizing the main insight in the chart>\n",
    "        Do not include any other trailing text after these two lines.\n",
    "        \"\"\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20286fcc-0d0b-4e24-88a7-621f3bbcea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_node(state: State) -> Command[Literal[\"chart_summarizer\"]]:\n",
    "    result = chart_agent.invoke(state)\n",
    "    # wrap in a human message, as not all providers allow\n",
    "    # AI message at the last position of the input messages list\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "    )\n",
    "    goto=\"chart_summarizer\"\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of chart agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a536526-0b2f-4f60-9b18-b205b4933ae7",
   "metadata": {},
   "source": [
    "2.6 Create chart summary agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c373c-b541-4b65-b995-4202a4e16505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ImageCaptionTool\n",
    "from langchain.tools import Tool\n",
    "\n",
    "chart_summary_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[\n",
    "        ImageCaptionTool(), \n",
    "        Tool.from_function(extract_chart_text_tool, name=\"ExtractChartText\"),\n",
    "    ],\n",
    "    prompt=agent_system_prompt(\n",
    "        \"You can only generate image captions. You are working with a researcher colleague and a chart generator colleague. \"\n",
    "        \"Your task is to generate a concise summary for the provided chart image at a local PATH, using visual and text information.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90b59e-556c-46c0-afa6-5c3f81d45499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_summary_node(\n",
    "    state: State,\n",
    ") -> Command[Literal[END]]:\n",
    "    result = chart_summary_agent.invoke(state)\n",
    "    print(f\"Chart summarizer answer: {result['messages'][-1].content}\")\n",
    "    # Send to the end node\n",
    "    goto = END\n",
    "    return Command(\n",
    "        update={\n",
    "            # share internal message history of chart agent with other agents\n",
    "            \"messages\": result[\"messages\"],\n",
    "            \"final_answer\": result[\"messages\"][-1].content,\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683a421-6c83-42b3-8bd7-8ee5a3efb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.7 Create a Synthesizer (Text Summarizer) Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d5e66-be5e-493d-90d1-cc8222a65b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d435e1-b852-41fe-b7fb-c5d39466160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesizer_node(state: State) -> Command[Literal[END]]:\n",
    "    \"\"\"\n",
    "    Creates a concise, humanâ€‘readable summary of the entire interaction,\n",
    "    **purely in prose**.\n",
    "\n",
    "    It ignores structured tables or chart IDs and instead rewrites the\n",
    "    relevant agent messages (research results, chart commentary, etc.)\n",
    "    into a short final answer.\n",
    "    \"\"\"\n",
    "    # Gather informative messages for final synthesis\n",
    "    relevant_msgs = [\n",
    "        m.content for m in state.get(\"messages\", [])\n",
    "        if getattr(m, \"name\", None) in (\"web_researcher\", \n",
    "                                        \"chart_generator\", \n",
    "                                        \"chart_summarizer\")\n",
    "    ]\n",
    "\n",
    "    user_question = state.get(\"user_query\", state.get(\"messages\", [{}])[0].content if state.get(\"messages\") else \"\")\n",
    "\n",
    "    synthesis_instructions = (\n",
    "        \"\"\"\n",
    "        You are the Synthesizer. Use the context below to directly \n",
    "        answer the user's question. Perform any lightweight calculations, \n",
    "        comparisons, or inferences required. Do not invent facts not \n",
    "        supported by the context. If data is missing, say what's missing\n",
    "        and, if helpful, offer a clearly labeled best-effort estimate \n",
    "        with assumptions.\\n\\n\n",
    "        Produce a concise response that fully answers the question, with \n",
    "        the following guidance:\\n\n",
    "        - Start with the direct answer (one short paragraph or a tight bullet list).\\n\n",
    "        - Include key figures from any 'Results:' tables (e.g., totals, top items).\\n\n",
    "        - If any message contains citations, include them as a brief 'Citations: [...]' line.\\n\n",
    "        - Keep the output crisp; avoid meta commentary or tool instructions.\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    summary_prompt = [\n",
    "        HumanMessage(content=(\n",
    "            f\"User question: {user_question}\\n\\n\"\n",
    "            f\"{synthesis_instructions}\\n\\n\"\n",
    "            f\"Context:\\n\\n\" + \"\\n\\n---\\n\\n\".join(relevant_msgs)\n",
    "        ))\n",
    "    ]\n",
    "\n",
    "    llm_reply = llm.invoke(summary_prompt)\n",
    "\n",
    "    answer = llm_reply.content.strip()\n",
    "    print(f\"Synthesizer answer: {answer}\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"final_answer\": answer,\n",
    "            \"messages\": [HumanMessage(content=answer, name=\"synthesizer\")],\n",
    "        },\n",
    "        goto=END,           # hand off to the END node\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e96853-34c3-455c-b551-783a080a3d1b",
   "metadata": {},
   "source": [
    "2.8 Build The agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7696c-3494-4f7a-82f7-f9c2bf221148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "workflow= StateGraph(State)\n",
    "workflow.add_node(\"planner\",planner_node)\n",
    "workflow.add_node(\"executor\",executor_node)\n",
    "workflow.add_node(\"web_researcher\",web_research_node)\n",
    "workflow.add_node(\"chart_generator\",chart_node)\n",
    "workflow.add_node(\"chart_summarizer\",chart_summary_node)\n",
    "workflow.add_node(\"synthesizer\",synthesizer_node)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "graph= workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce949d-e27b-40e9-ac2b-76a1232069bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b87d93-acc6-461c-bc1b-b061f3d345e0",
   "metadata": {},
   "source": [
    "2.9 Use the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32531e04-68b7-4680-ae1b-3c6ddcff85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "import json\n",
    "query = \"Chart the current market capitalization of the top 5 semiconductor industries in the US?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"user_query\": query,\n",
    "            \"enabled_agents\": [\"web_researcher\", \"chart_generator\", \n",
    "                               \"chart_summarizer\", \"synthesizer\"],\n",
    "        }\n",
    "graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080701b-08a2-40c6-ae2e-e14d8d1097a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Identify current regulatory changes for the industrial services industry in the US.\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "state = {\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"user_query\": query,\n",
    "            \"enabled_agents\": [\"web_researcher\", \"chart_generator\", \n",
    "                               \"chart_summarizer\", \"synthesizer\"],\n",
    "        }\n",
    "graph.invoke(state)\n",
    "\n",
    "print(\"--------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
